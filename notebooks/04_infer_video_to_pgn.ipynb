{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 — Infer Videos → PGN (Submission)\n",
        "\n",
        "Use board warp + per‑cell CNN + rule engine to output PGN per video.\n",
        "\n",
        "- Reads videos from `data/public/videos/*.mp4` (local) or a Kaggle input path you specify.\n",
        "- Loads model from `models/cell_cnn.h5`.\n",
        "- Writes `submissions/submission.csv` with `row_id,output`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install --quiet opencv-python python-chess tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded classes from classes.json: ['BB', 'BK', 'BN', 'BP', 'BQ', 'BR', 'Empty', 'WB', 'WK', 'WN', 'WP', 'WQ', 'WR']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: model outputs 13 classes.\n",
            "=== Environment ===\n",
            "Kaggle     : False\n",
            "ROOT       : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\n",
            "Config     : configs/parameters.yaml\n",
            "Model path : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\models\\cell_cnn.h5 exists? True\n",
            "IMG_SIZE   : 96\n",
            "Videos dir : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\public\\videos | found: 5\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 04 — Setup & Bootstrap\n",
        "# =========================\n",
        "\n",
        "# --- stdlib / third-party ---\n",
        "import os, sys, json, csv\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- TF / Keras ---\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input # type: ignore\n",
        "\n",
        "# --- env: local vs Kaggle ---\n",
        "ON_KAGGLE = Path(\"/kaggle\").exists()\n",
        "ROOT = Path(\"/kaggle/working\") if ON_KAGGLE else Path(\"..\").resolve()\n",
        "\n",
        "# ให้ import โค้ดจากโปรเจกต์ได้ (ทั้งแบบแพ็กเกจและแบบ src/)\n",
        "sys.path.insert(0, str(ROOT / \"src\"))\n",
        "sys.path.insert(0, str(ROOT))\n",
        "\n",
        "# --- project modules ---\n",
        "from Chess_Detection_Competition.utils import load_config\n",
        "from Chess_Detection_Competition.board import warp_board, split_grid\n",
        "from Chess_Detection_Competition.model import load_model as load_cell_model\n",
        "from Chess_Detection_Competition.pgn import diff_to_move, san_list_to_pgn, labels_to_board\n",
        "\n",
        "# --- paths ---\n",
        "VIDEOS_DIR   = ROOT / \"data/public/videos\"   # input videos\n",
        "MODEL_PATH   = ROOT / \"models/cell_cnn.h5\"   # trained model (.h5)\n",
        "CLASSES_JSON = ROOT / \"models/classes.json\"  # class order saved at training time\n",
        "TRAIN_DIR    = ROOT / \"data/final/train\"     # fallback only (avoid if classes.json exists)\n",
        "OUT_DIR      = ROOT / \"submissions\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUBMIT_CSV   = OUT_DIR / \"submission.csv\"\n",
        "\n",
        "# --- load config (board/cell/inference params) ---\n",
        "try:\n",
        "    cfg = load_config()  # configs/parameters.yaml\n",
        "    BOARD_CFG   = cfg[\"board\"]\n",
        "    IMG_SIZE    = int(cfg[\"cells\"][\"img_size\"])\n",
        "    SMOOTH_K    = int(cfg[\"inference\"][\"smooth_k\"])\n",
        "    SAMPLE_STEP = int(cfg[\"inference\"][\"sample_step\"])\n",
        "    cfg_source  = \"configs/parameters.yaml\"\n",
        "except Exception as e:\n",
        "    BOARD_CFG = {\n",
        "        \"warp_size\": 800,\n",
        "        \"canny_low\": 60,\n",
        "        \"canny_high\": 180,\n",
        "        \"hough_threshold\": 120,\n",
        "        \"min_line_length\": 120,\n",
        "        \"max_line_gap\": 10,\n",
        "    }\n",
        "    IMG_SIZE, SMOOTH_K, SAMPLE_STEP = 96, 5, 3\n",
        "    cfg_source = f\"[fallback defaults] ({e})\"\n",
        "\n",
        "# --- load class order (MUST match training) ---\n",
        "if CLASSES_JSON.exists():\n",
        "    CLASSES = json.loads(CLASSES_JSON.read_text(encoding=\"utf-8\"))\n",
        "    print(\"Loaded classes from classes.json:\", CLASSES)\n",
        "else:\n",
        "    # Fallback (ไม่แนะนำ): เดาจากโฟลเดอร์ train ตาม sorting ของ Keras\n",
        "    subdirs = [p.name for p in TRAIN_DIR.iterdir() if p.is_dir()] if TRAIN_DIR.exists() else []\n",
        "    CLASSES = sorted(subdirs)\n",
        "    print(\"[WARN] classes.json missing. Inferred classes:\", CLASSES)\n",
        "\n",
        "# --- load trained cell-CNN ---\n",
        "model = load_cell_model(str(MODEL_PATH))\n",
        "try:\n",
        "    num_out = model.output_shape[-1]\n",
        "    assert num_out == len(CLASSES), (\n",
        "        f\"Model output ({num_out}) != num classes ({len(CLASSES)}) \"\n",
        "        f\"→ ใช้ classes.json ที่ได้จากรันเทรนเดียวกัน\"\n",
        "    )\n",
        "    print(f\"OK: model outputs {num_out} classes.\")\n",
        "except Exception as e:\n",
        "    print(\"[WARN] cannot verify model output vs classes:\", e)\n",
        "\n",
        "# --- debug helpers ---\n",
        "def _dbg(s): print(\"[DBG]\", s)\n",
        "\n",
        "def _mask_changes(a, b):\n",
        "    return np.array([[a[r][c] != b[r][c] for c in range(8)] for r in range(8)], dtype=bool)\n",
        "\n",
        "def _diff_preview(prev_labels, now_labels, mask=None, max_list=8):\n",
        "    rows, coords = [], []\n",
        "    for r in range(8):\n",
        "        marks = []\n",
        "        for c in range(8):\n",
        "            changed = (prev_labels[r][c] != now_labels[r][c])\n",
        "            if mask is not None:\n",
        "                changed = changed and bool(mask[r, c])\n",
        "            marks.append(\"X\" if changed else \".\")\n",
        "            if changed:\n",
        "                coords.append((r, c, prev_labels[r][c], now_labels[r][c]))\n",
        "        rows.append(\" \".join(marks))\n",
        "    for s in rows: _dbg(s)\n",
        "    if coords:\n",
        "        _dbg(\"changes (r,c: prev→now):\")\n",
        "        for (r,c,a,b) in coords[:max_list]:\n",
        "            _dbg(f\"  ({r},{c}): {a} → {b}\")\n",
        "        if len(coords) > max_list:\n",
        "            _dbg(f\"  ... (+{len(coords)-max_list} more)\")\n",
        "\n",
        "# --- Homography bootstrap (FORCE_H0) ---\n",
        "FORCE_H0 = None\n",
        "FORCE_WARP_SIZE = None  # (W,H)\n",
        "\n",
        "def scan_for_H0(video_path: Path, max_scan=120, step=2):\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    H0, wh = None, None\n",
        "    f = 0\n",
        "    while f < max_scan:\n",
        "        ok = cap.grab()\n",
        "        if not ok: break\n",
        "        f += 1\n",
        "        if f % step: continue\n",
        "        ok, frame = cap.retrieve()\n",
        "        if not ok or frame is None: continue\n",
        "        warped, aux = warp_board(frame, {\"board\": BOARD_CFG})\n",
        "        if warped is not None and getattr(warped, \"size\", 0) > 0 and isinstance(aux, dict) and aux.get(\"H\") is not None:\n",
        "            H0 = aux[\"H\"]\n",
        "            wh = (warped.shape[1], warped.shape[0])\n",
        "            print(f\"[HBOOT] Found H at frame {f}: size={wh}\")\n",
        "            break\n",
        "    cap.release()\n",
        "    if H0 is None:\n",
        "        print(f\"[HBOOT] No H found in first ~{max_scan} frames\")\n",
        "    return H0, wh\n",
        "\n",
        "def run_video_with_homography(video_path: Path):\n",
        "    global FORCE_H0, FORCE_WARP_SIZE\n",
        "    FORCE_H0, FORCE_WARP_SIZE = scan_for_H0(video_path, max_scan=120, step=2)\n",
        "    if FORCE_H0 is None:\n",
        "        print(\"[HBOOT] Proceeding WITHOUT fixed H (results may be noisy)\")\n",
        "    else:\n",
        "        print(\"[HBOOT] Using fixed H for all frames\")\n",
        "    pgn = decode_video_to_pgn(video_path)  # type: ignore[name-defined]\n",
        "    FORCE_H0, FORCE_WARP_SIZE = None, None  # reset\n",
        "    return pgn\n",
        "\n",
        "# --- environment summary ---\n",
        "video_files = sorted(VIDEOS_DIR.glob(\"*.mp4\"))\n",
        "print(\"=== Environment ===\")\n",
        "print(\"Kaggle     :\", ON_KAGGLE)\n",
        "print(\"ROOT       :\", ROOT)\n",
        "print(\"Config     :\", cfg_source)\n",
        "print(\"Model path :\", MODEL_PATH, \"exists?\", MODEL_PATH.exists())\n",
        "print(\"IMG_SIZE   :\", IMG_SIZE)\n",
        "print(\"Videos dir :\", VIDEOS_DIR, \"| found:\", len(video_files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Inference helpers & tunables\n",
        "# =========================\n",
        "import chess\n",
        "from copy import deepcopy\n",
        "\n",
        "# ---- Tunables ----\n",
        "TAU = 0.45                   # thresh ความมั่นใจต่อ cell\n",
        "SMOOTH_K = max(9, int(SMOOTH_K))  # moving average per-cell\n",
        "SETTLE = 15                  # warm-up frames\n",
        "SAMPLE_STEP = 1              # อ่านทุกเฟรม\n",
        "MIN_CH, MAX_CH = 2, 8        # เกณฑ์จำนวนช่องที่ควรเปลี่ยนใน 1 move\n",
        "PENDING_HORIZON = 2\n",
        "ENFORCE_LEGAL = True         # ใช้กฎหมากรุกจริง\n",
        "REQUIRE_STABLE_FRAMES = 2    # label ใหม่ต้องคงอยู่กี่เฟรม ถึงจะยอม “เปลี่ยน”\n",
        "\n",
        "def predict_labels8x8_with_conf(warped_bgr, buffers):\n",
        "    cells = split_grid(warped_bgr, IMG_SIZE)\n",
        "    X = []\n",
        "    for _, patch in cells:\n",
        "        rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        X.append(preprocess_input(rgb))\n",
        "    X = np.asarray(X, dtype=np.float32)\n",
        "    probs = model.predict(X, verbose=0)  # (64, C)\n",
        "\n",
        "    labels = [[None]*8 for _ in range(8)]\n",
        "    confs  = np.zeros((8, 8), dtype=np.float32)\n",
        "    k = 0\n",
        "    for r in range(8):\n",
        "        for c in range(8):\n",
        "            buffers[r][c].append(probs[k])\n",
        "            avg = np.mean(np.stack(buffers[r][c], axis=0), axis=0)\n",
        "            idx = int(np.argmax(avg))\n",
        "            labels[r][c] = CLASSES[idx]\n",
        "            confs[r, c]  = float(avg[idx])\n",
        "            k += 1\n",
        "    return labels, confs\n",
        "\n",
        "# ---- legal-move resolver ----\n",
        "def rc_to_square(r, c):\n",
        "    file = c\n",
        "    rank = 7 - r\n",
        "    return chess.square(file, rank)\n",
        "\n",
        "def find_from_to_pair(prev_labels, now_labels, eff_mask):\n",
        "    srcs, dsts = [], []\n",
        "    for r in range(8):\n",
        "        for c in range(8):\n",
        "            if not eff_mask[r, c]:\n",
        "                continue\n",
        "            a, b = prev_labels[r][c], now_labels[r][c]\n",
        "            if a != \"Empty\" and b == \"Empty\":\n",
        "                srcs.append((r, c, a))\n",
        "            if a == \"Empty\" and b != \"Empty\":\n",
        "                dsts.append((r, c, b))\n",
        "    if not srcs or not dsts:\n",
        "        return None\n",
        "    best, best_d = None, 1e9\n",
        "    for (rs, cs, pa) in srcs:\n",
        "        for (rd, cd, pb) in dsts:\n",
        "            d = abs(rs - rd) + abs(cs - cd)\n",
        "            if d < best_d:\n",
        "                best_d = d\n",
        "                best = ((rs, cs, pa), (rd, cd, pb))\n",
        "    return best\n",
        "\n",
        "def make_move_candidates(rs, cs, rd, cd, try_promos=(\"Q\",\"R\",\"B\",\"N\")):\n",
        "    from_sq = rc_to_square(rs, cs)\n",
        "    to_sq   = rc_to_square(rd, cd)\n",
        "    cands = [chess.Move(from_sq, to_sq)]\n",
        "    for sym in try_promos:\n",
        "        promo = {\"Q\": chess.QUEEN, \"R\": chess.ROOK, \"B\": chess.BISHOP, \"N\": chess.KNIGHT}[sym]\n",
        "        cands.append(chess.Move(from_sq, to_sq, promotion=promo))\n",
        "    return cands\n",
        "\n",
        "def resolve_move_by_legality(prev_labels, now_labels, eff_mask, try_promos=(\"Q\",\"R\",\"B\",\"N\")):\n",
        "    b_prev = labels_to_board(prev_labels)\n",
        "    pair = find_from_to_pair(prev_labels, now_labels, eff_mask)\n",
        "    if pair is None:\n",
        "        return None\n",
        "    (rs, cs, _), (rd, cd, _) = pair\n",
        "    candidates = make_move_candidates(rs, cs, rd, cd, try_promos=try_promos)\n",
        "    legal = set(b_prev.legal_moves)\n",
        "    for mv in candidates:\n",
        "        if mv in legal:\n",
        "            return mv\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Main inference: decode_video_to_pgn\n",
        "# =========================\n",
        "from copy import deepcopy\n",
        "\n",
        "def decode_video_to_pgn(video_path: Path) -> str:\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    ok, frame0 = cap.read()\n",
        "    if not ok or frame0 is None:\n",
        "        _dbg(f\"read fail: {video_path.name}\")\n",
        "        cap.release(); return \"\"\n",
        "\n",
        "    # ใช้ FORCE_H0 ถ้ามี\n",
        "    if FORCE_H0 is not None and FORCE_WARP_SIZE is not None:\n",
        "        warped0 = cv2.warpPerspective(frame0, FORCE_H0, FORCE_WARP_SIZE)\n",
        "        aux0 = {\"H\": FORCE_H0}\n",
        "        _dbg(\"[HUSE] using FORCE_H0 on frame0\")\n",
        "    else:\n",
        "        warped0, aux0 = warp_board(frame0, {\"board\": BOARD_CFG})\n",
        "\n",
        "    if warped0 is None or getattr(warped0, \"size\", 0) == 0:\n",
        "        _dbg(f\"warp fail: {video_path.name}\")\n",
        "        cap.release(); return \"\"\n",
        "\n",
        "    H0 = aux0.get(\"H\") if isinstance(aux0, dict) else None\n",
        "    _dbg(f\"frame0 shape={frame0.shape}, warped shape={warped0.shape}, have H? {H0 is not None}\")\n",
        "\n",
        "    # buffers & state\n",
        "    buffers = [[deque(maxlen=SMOOTH_K) for _ in range(8)] for __ in range(8)]\n",
        "    stable = [[None]*8 for _ in range(8)]\n",
        "    steady = [[0]*8 for _ in range(8)]\n",
        "\n",
        "    prev_labels, prev_confs = predict_labels8x8_with_conf(warped0, buffers)\n",
        "    for r in range(8):\n",
        "        for c in range(8):\n",
        "            stable[r][c] = prev_labels[r][c]\n",
        "            steady[r][c] = REQUIRE_STABLE_FRAMES\n",
        "    _dbg(f\"first labels sample: {prev_labels[0][:4]} ...\")\n",
        "\n",
        "    # warm-up\n",
        "    for _ in range(SETTLE):\n",
        "        ok, fr = cap.read()\n",
        "        if not ok: break\n",
        "        if FORCE_H0 is not None and FORCE_WARP_SIZE is not None:\n",
        "            warped = cv2.warpPerspective(fr, FORCE_H0, FORCE_WARP_SIZE)\n",
        "        else:\n",
        "            warped = cv2.warpPerspective(fr, H0, (warped0.shape[1], warped0.shape[0])) if H0 is not None else warp_board(fr, {\"board\": BOARD_CFG})[0]\n",
        "        if warped is None or getattr(warped, \"size\", 0) == 0:\n",
        "            continue\n",
        "        _ = predict_labels8x8_with_conf(warped, buffers)\n",
        "\n",
        "    sans = []\n",
        "    frame_id = SETTLE\n",
        "    pending = None\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "        frame_id += 1\n",
        "        if frame_id % SAMPLE_STEP:\n",
        "            continue\n",
        "\n",
        "        if FORCE_H0 is not None and FORCE_WARP_SIZE is not None:\n",
        "            warped = cv2.warpPerspective(frame, FORCE_H0, FORCE_WARP_SIZE)\n",
        "        else:\n",
        "            warped = cv2.warpPerspective(frame, H0, (warped0.shape[1], warped0.shape[0])) if H0 is not None else warp_board(frame, {\"board\": BOARD_CFG})[0]\n",
        "\n",
        "        if warped is None or getattr(warped, \"size\", 0) == 0:\n",
        "            _dbg(f\"warp fail midstream @ f{frame_id}\")\n",
        "            continue\n",
        "\n",
        "        now_labels_raw, now_confs = predict_labels8x8_with_conf(warped, buffers)\n",
        "\n",
        "        # sticky โดย TAU\n",
        "        sticky = [[now_labels_raw[r][c] if now_confs[r, c] >= TAU else stable[r][c]\n",
        "                   for c in range(8)] for r in range(8)]\n",
        "\n",
        "        # per-cell stability\n",
        "        for r in range(8):\n",
        "            for c in range(8):\n",
        "                if sticky[r][c] == stable[r][c]:\n",
        "                    steady[r][c] = min(steady[r][c] + 1, REQUIRE_STABLE_FRAMES)\n",
        "                else:\n",
        "                    steady[r][c] = 1\n",
        "                if steady[r][c] >= REQUIRE_STABLE_FRAMES:\n",
        "                    stable[r][c] = sticky[r][c]\n",
        "\n",
        "        # diff + gating\n",
        "        conf_or = (prev_confs >= TAU) | (now_confs >= TAU)\n",
        "        diff_raw = _mask_changes(stable, sticky)\n",
        "        eff_mask = conf_or & diff_raw\n",
        "        changes_eff = int(eff_mask.sum())\n",
        "        if frame_id % (5 * max(1, SAMPLE_STEP)) == 0:\n",
        "            _dbg(f\"f{frame_id}: changes_eff={changes_eff}\")\n",
        "\n",
        "        committed = False\n",
        "        if MIN_CH <= changes_eff <= MAX_CH:\n",
        "            mv = diff_to_move(stable, sticky)\n",
        "            if ENFORCE_LEGAL and mv is None:\n",
        "                try_promos = tuple(cfg.get(\"pgn\", {}).get(\"try_promotions\", [\"Q\",\"R\",\"B\",\"N\"]))\n",
        "                mv = resolve_move_by_legality(stable, sticky, eff_mask, try_promos=try_promos)\n",
        "\n",
        "            if mv is not None:\n",
        "                b_prev = labels_to_board(stable)\n",
        "                try:\n",
        "                    san = b_prev.san(mv)\n",
        "                except Exception as e:\n",
        "                    _dbg(f\"SAN fail @ f{frame_id}: {e}\")\n",
        "                    _diff_preview(stable, sticky, eff_mask)\n",
        "                else:\n",
        "                    sans.append(san)\n",
        "                    _dbg(f\"f{frame_id}: SAN={san} (eff={changes_eff})\")\n",
        "                    prev_labels = deepcopy(sticky)\n",
        "                    prev_confs = now_confs.copy()\n",
        "                    stable = deepcopy(sticky)\n",
        "                    steady = [[REQUIRE_STABLE_FRAMES]*8 for _ in range(8)]\n",
        "                    pending = None\n",
        "                    committed = True\n",
        "            else:\n",
        "                _dbg(f\"f{frame_id}: no {'legal ' if ENFORCE_LEGAL else ''}move matched (eff={changes_eff})\")\n",
        "                _diff_preview(stable, sticky, eff_mask)\n",
        "                pending = {\"frame\": frame_id, \"labels\": deepcopy(stable), \"mask\": eff_mask.copy()}\n",
        "\n",
        "        # pending combine\n",
        "        if not committed and pending is not None and (frame_id - pending[\"frame\"]) <= PENDING_HORIZON:\n",
        "            combined_mask = pending[\"mask\"] | eff_mask\n",
        "            combined_changes = int(combined_mask.sum())\n",
        "            mv2 = diff_to_move(stable, sticky)\n",
        "            if ENFORCE_LEGAL and mv2 is None:\n",
        "                try_promos = tuple(cfg.get(\"pgn\", {}).get(\"try_promotions\", [\"Q\",\"R\",\"B\",\"N\"]))\n",
        "                mv2 = resolve_move_by_legality(stable, sticky, combined_mask, try_promos=try_promos)\n",
        "            if mv2 is not None:\n",
        "                b_prev = labels_to_board(stable)\n",
        "                try:\n",
        "                    san = b_prev.san(mv2)\n",
        "                except Exception as e:\n",
        "                    _dbg(f\"SAN fail (pending) @ f{frame_id}: {e}\")\n",
        "                    _diff_preview(stable, sticky, combined_mask)\n",
        "                else:\n",
        "                    sans.append(san)\n",
        "                    _dbg(f\"f{frame_id}: SAN={san} (pending, combined={combined_changes})\")\n",
        "                    prev_labels = deepcopy(sticky)\n",
        "                    prev_confs = now_confs.copy()\n",
        "                    stable = deepcopy(sticky)\n",
        "                    steady = [[REQUIRE_STABLE_FRAMES]*8 for _ in range(8)]\n",
        "                    pending = None\n",
        "\n",
        "        if pending is not None and (frame_id - pending[\"frame\"]) > PENDING_HORIZON:\n",
        "            pending = None\n",
        "\n",
        "    cap.release()\n",
        "    _dbg(f\"done. total SAN moves = {len(sans)}\")\n",
        "    if sans: _dbg(f\"first SAN moves = {sans[:10]}\")\n",
        "    try:\n",
        "        return san_list_to_pgn(sans)\n",
        "    except Exception as e:\n",
        "        _dbg(f\"san_list_to_pgn error: {e}\")\n",
        "        return \" \".join(sans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "videos: 5\n",
            "TEST: 2_Move_rotate_student.mp4\n",
            "[HBOOT] No H found in first ~120 frames\n",
            "[HBOOT] Proceeding WITHOUT fixed H (results may be noisy)\n",
            "[DBG] frame0 shape=(1920, 1080, 3), warped shape=(800, 800, 3), have H? False\n",
            "[DBG] first labels sample: ['WN', 'BN', 'BB', 'BQ'] ...\n",
            "[DBG] f20: changes_eff=10\n",
            "[DBG] f25: changes_eff=12\n",
            "[DBG] f30: changes_eff=11\n",
            "[DBG] f35: changes_eff=8\n",
            "[DBG] f35: no legal move matched (eff=8)\n",
            "[DBG] X . . . . . . .\n",
            "[DBG] . . X . . . X .\n",
            "[DBG] . . . . . . . .\n",
            "[DBG] X X . . . . X .\n",
            "[DBG] . . . . . . . .\n",
            "[DBG] . . . . . . . .\n",
            "[DBG] . X . . . . . .\n",
            "[DBG] . . . . X . . .\n",
            "[DBG] changes (r,c: prev→now):\n",
            "[DBG]   (0,0): WN → WR\n",
            "[DBG]   (1,2): WP → BP\n",
            "[DBG]   (1,6): BP → Empty\n",
            "[DBG]   (3,0): BP → Empty\n",
            "[DBG]   (3,1): Empty → BP\n",
            "[DBG]   (3,6): Empty → WP\n",
            "[DBG]   (6,1): Empty → BP\n",
            "[DBG]   (7,4): WP → Empty\n",
            "[DBG] f40: changes_eff=11\n",
            "[DBG] f45: changes_eff=15\n",
            "[DBG] f50: changes_eff=12\n",
            "[DBG] f55: changes_eff=13\n",
            "[DBG] f60: changes_eff=18\n",
            "[DBG] f65: changes_eff=14\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m     SMOOTH_K = \u001b[32m1\u001b[39m\n\u001b[32m     12\u001b[39m     SAMPLE_STEP = \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     pgn = \u001b[43mrun_video_with_homography\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPGN =\u001b[39m\u001b[33m\"\u001b[39m, pgn \u001b[38;5;28;01mif\u001b[39;00m pgn \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m[EMPTY]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mrun_video_with_homography\u001b[39m\u001b[34m(video_path)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[HBOOT] Using fixed H for all frames\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m pgn = \u001b[43mdecode_video_to_pgn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[name-defined]\u001b[39;00m\n\u001b[32m    142\u001b[39m FORCE_H0, FORCE_WARP_SIZE = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# reset\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pgn\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mdecode_video_to_pgn\u001b[39m\u001b[34m(video_path)\u001b[39m\n\u001b[32m     64\u001b[39m     warped = cv2.warpPerspective(frame, FORCE_H0, FORCE_WARP_SIZE)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     warped = cv2.warpPerspective(frame, H0, (warped0.shape[\u001b[32m1\u001b[39m], warped0.shape[\u001b[32m0\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m H0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mwarp_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboard\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mBOARD_CFG\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m warped \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(warped, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) == \u001b[32m0\u001b[39m:\n\u001b[32m     69\u001b[39m     _dbg(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwarp fail midstream @ f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\src\\Chess_Detection_Competition\\board.py:294\u001b[39m, in \u001b[36mwarp_board\u001b[39m\u001b[34m(bgr, cfg)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwarp_board\u001b[39m(bgr, cfg=DEFAULT_CFG):\n\u001b[32m    293\u001b[39m     w = cfg[\u001b[33m\"\u001b[39m\u001b[33mboard\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mwarp_size\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     src = \u001b[43m_find_board_corners\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     dst = np.float32([[\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m],[w,\u001b[32m0\u001b[39m],[w,w],[\u001b[32m0\u001b[39m,w]])\n\u001b[32m    296\u001b[39m     M = cv2.getPerspectiveTransform(src, dst)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\src\\Chess_Detection_Competition\\board.py:289\u001b[39m, in \u001b[36m_find_board_corners\u001b[39m\u001b[34m(bgr, cfg)\u001b[39m\n\u001b[32m    286\u001b[39m     rough = corners  \u001b[38;5;66;03m# edges ทำบนภาพเต็มอยู่แล้ว\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# 2) refine ด้วย checker energy\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m final = \u001b[43mrefine_by_checker_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrough\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\src\\Chess_Detection_Competition\\board.py:254\u001b[39m, in \u001b[36mrefine_by_checker_energy\u001b[39m\u001b[34m(bgr, rough_corners, grid, cfg)\u001b[39m\n\u001b[32m    252\u001b[39m M = cv2.getPerspectiveTransform(C.astype(np.float32), dst)\n\u001b[32m    253\u001b[39m warped = cv2.warpPerspective(bgr, M, (w,w))\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m score = \u001b[43m_checker_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score > best_score:\n\u001b[32m    256\u001b[39m     best_score = score\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\src\\Chess_Detection_Competition\\board.py:217\u001b[39m, in \u001b[36m_checker_energy\u001b[39m\u001b[34m(warped)\u001b[39m\n\u001b[32m    215\u001b[39m G = cv2.resize(g, (cell*\u001b[32m8\u001b[39m, cell*\u001b[32m8\u001b[39m), interpolation=cv2.INTER_AREA)\n\u001b[32m    216\u001b[39m G = (G - G.mean()) / (G.std()+\u001b[32m1e-6\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mabs\u001b[39m(\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\.venv312\\Lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     51\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Quick test one video (uses fixed H0)\n",
        "# =========================\n",
        "video_files = sorted(VIDEOS_DIR.glob(\"*.mp4\"))\n",
        "print(\"videos:\", len(video_files))\n",
        "\n",
        "if video_files:\n",
        "    p = video_files[0]\n",
        "    print(\"TEST:\", p.name)\n",
        "    # ให้เห็น log ชัด ๆ ระหว่างทดสอบ\n",
        "    SMOOTH_K = 1\n",
        "    SAMPLE_STEP = 1\n",
        "    pgn = run_video_with_homography(p)\n",
        "    print(\"\\nPGN =\", pgn if pgn else \"[EMPTY]\")\n",
        "else:\n",
        "    print(\"[WARN] no videos found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "video_files = sorted(VIDEOS_DIR.glob(\"*.mp4\"))\n",
        "if not video_files:\n",
        "    print(f\"[warn] no videos found in: {VIDEOS_DIR}\")\n",
        "\n",
        "for v in tqdm(video_files, desc=\"Decoding videos\"):\n",
        "    row_id = v.stem\n",
        "    pgn = decode_video_to_pgn(v)\n",
        "    rows.append((row_id, pgn))\n",
        "    print(f\"{row_id} -> {pgn}\")\n",
        "\n",
        "with open(SUBMIT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"row_id\", \"output\"])\n",
        "    w.writerows(rows)\n",
        "\n",
        "print(\"✅ submission saved to:\", SUBMIT_CSV.resolve())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv312 (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
