{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 — Infer Videos → PGN (Submission)\n",
        "\n",
        "Use board warp + per‑cell CNN + rule engine to output PGN per video.\n",
        "\n",
        "- Reads videos from `data/public/videos/*.mp4` (local) or a Kaggle input path you specify.\n",
        "- Loads model from `models/cell_cnn.h5`.\n",
        "- Writes `submissions/submission.csv` with `row_id,output`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install --quiet opencv-python python-chess tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Environment ===\n",
            "Kaggle     : False\n",
            "ROOT       : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\n",
            "Config     : configs/parameters.yaml\n",
            "Videos dir : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\public\\videos\n",
            "Model path : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\models\\cell_cnn.h5\n",
            "Submit CSV : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\submissions\\submission.csv\n",
            "Train dir  : C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\final\\train\n",
            "IMG_SIZE   : 96\n",
            "SMOOTH_K   : 5\n",
            "SAMPLE_STEP: 3\n",
            "Classes    : ['BB', 'BK', 'BN', 'BP', 'BQ', 'BR', 'Empty', 'WB', 'WK', 'WN', 'WP', 'WQ', 'WR']\n",
            "Videos found: 5\n"
          ]
        }
      ],
      "source": [
        "# # --- imports & env ---\n",
        "# import os, sys, csv\n",
        "# from pathlib import Path\n",
        "# import json\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from collections import deque\n",
        "# from tqdm import tqdm\n",
        "# from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# # --- env / root selection (local vs Kaggle) ---\n",
        "# ON_KAGGLE = Path('/kaggle').exists()\n",
        "# ROOT = Path('/kaggle/working') if ON_KAGGLE else Path('..')\n",
        "\n",
        "# # ให้ import แพ็กเกจจากโฟลเดอร์ src ได้ (เหมือนโน้ตบุ๊กก่อนหน้า)\n",
        "# sys.path.insert(0, str(ROOT / 'src'))\n",
        "\n",
        "# # --- project modules ---\n",
        "# from Chess_Detection_Competition.utils import load_config\n",
        "# from Chess_Detection_Competition.board import warp_board, split_grid\n",
        "# from Chess_Detection_Competition.model import load_model as load_cell_model\n",
        "# from Chess_Detection_Competition.pgn import diff_to_move, san_list_to_pgn, labels_to_board\n",
        "\n",
        "# # --- paths ---\n",
        "# VIDEOS_DIR = ROOT / 'data/public/videos'          # เปลี่ยนตรงนี้ได้ถ้าใช้ input ของ Kaggle competition\n",
        "# MODEL_PATH = ROOT / 'models/cell_cnn.h5'\n",
        "# CLASSES_JSON = ROOT / 'models/classes.json'\n",
        "# OUT_DIR    = ROOT / 'submissions'\n",
        "# OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "# SUBMIT_CSV = OUT_DIR / 'submission.csv'\n",
        "\n",
        "# # --- load config / params ---\n",
        "# cfg = load_config()  # อ่าน configs/parameters.yaml\n",
        "# BOARD_CFG = cfg[\"board\"]\n",
        "# IMG_SIZE  = cfg[\"cells\"][\"img_size\"]\n",
        "# SMOOTH_K  = cfg[\"inference\"][\"smooth_k\"]\n",
        "# SAMPLE_STEP = cfg[\"inference\"][\"sample_step\"]\n",
        "\n",
        "# # --- load class order (ต้องตรงกับตอนเทรน) ---\n",
        "# if CLASSES_JSON.exists():\n",
        "#     with open(CLASSES_JSON, \"r\", encoding=\"utf-8\") as f:\n",
        "#         CLASSES = json.load(f)\n",
        "# else:\n",
        "#     # ถ้าไม่มีไฟล์นี้ ให้ใช้ลำดับคลาสเดียวกับที่เทรนประกาศไว้ในโปรเจกต์\n",
        "#     CLASSES = ['BB','BK','BN','BP','BQ','BR','Empty','WB','WK','WN','WP','WQ','WR']\n",
        "\n",
        "# print(\"Videos :\", VIDEOS_DIR.resolve())\n",
        "# print(\"Model  :\", MODEL_PATH.resolve())\n",
        "# print(\"Submit :\", SUBMIT_CSV.resolve())\n",
        "# print(\"Classes:\", CLASSES)\n",
        "\n",
        "# =========================\n",
        "# 04 — Setup (robust & auto)\n",
        "# =========================\n",
        "\n",
        "# --- stdlib / third-party ---\n",
        "import os, sys, csv, json\n",
        "from pathlib import Path\n",
        "from collections import deque\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# --- env: local vs Kaggle ---\n",
        "ON_KAGGLE = Path(\"/kaggle\").exists()\n",
        "ROOT = Path(\"/kaggle/working\") if ON_KAGGLE else Path(\"..\").resolve()\n",
        "\n",
        "# ให้ import จากโฟลเดอร์ src และแพ็กเกจในโปรเจกต์ได้ (กันพลาดทั้งสองแบบ)\n",
        "sys.path.insert(0, str(ROOT / \"src\"))\n",
        "sys.path.insert(0, str(ROOT))\n",
        "\n",
        "# --- project modules (with safe import) ---\n",
        "try:\n",
        "    from Chess_Detection_Competition.utils import load_config\n",
        "    from Chess_Detection_Competition.board import warp_board, split_grid\n",
        "    from Chess_Detection_Competition.model import load_model as load_cell_model\n",
        "    from Chess_Detection_Competition.pgn import diff_to_move, san_list_to_pgn, labels_to_board\n",
        "except Exception as e:\n",
        "    # เผื่อบางเครื่องยังไม่ได้ pip install -e .\n",
        "    # ลอง import แบบโมดูลใน src โดยตรง\n",
        "    from Chess_Detection_Competition.utils import load_config  # จะสำเร็จเพราะ sys.path ใส่ ROOT/src ไว้แล้ว\n",
        "    from Chess_Detection_Competition.board import warp_board, split_grid\n",
        "    from Chess_Detection_Competition.model import load_model as load_cell_model\n",
        "    from Chess_Detection_Competition.pgn import diff_to_move, san_list_to_pgn, labels_to_board\n",
        "\n",
        "# --- paths ---\n",
        "VIDEOS_DIR   = ROOT / \"data/public/videos\"     # วิดีโอ input\n",
        "MODEL_PATH   = ROOT / \"models/cell_cnn.h5\"     # ไฟล์โมเดลที่เทรน\n",
        "CLASSES_JSON = ROOT / \"models/classes.json\"    # เก็บลำดับคลาสตอนเทรน\n",
        "TRAIN_DIR    = ROOT / \"data/final/train\"       # ใช้เดาจากโฟลเดอร์ (fallback)\n",
        "OUT_DIR      = ROOT / \"submissions\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUBMIT_CSV   = OUT_DIR / \"submission.csv\"\n",
        "\n",
        "# --- load config (fallback ให้ค่าเริ่มต้นถ้าไม่มีไฟล์) ---\n",
        "try:\n",
        "    cfg = load_config()  # configs/parameters.yaml\n",
        "    BOARD_CFG   = cfg[\"board\"]\n",
        "    IMG_SIZE    = int(cfg[\"cells\"][\"img_size\"])\n",
        "    SMOOTH_K    = int(cfg[\"inference\"][\"smooth_k\"])\n",
        "    SAMPLE_STEP = int(cfg[\"inference\"][\"sample_step\"])\n",
        "    cfg_source  = \"configs/parameters.yaml\"\n",
        "except Exception as e:\n",
        "    # ค่า default ที่ใช้ได้จริง\n",
        "    BOARD_CFG = {\n",
        "        \"warp_size\": 800,\n",
        "        \"canny_low\": 60,\n",
        "        \"canny_high\": 180,\n",
        "        \"hough_threshold\": 120,\n",
        "        \"min_line_length\": 120,\n",
        "        \"max_line_gap\": 10,\n",
        "    }\n",
        "    IMG_SIZE, SMOOTH_K, SAMPLE_STEP = 96, 5, 3\n",
        "    cfg_source = f\"[fallback defaults] ({e})\"\n",
        "\n",
        "# --- resolve class order (ต้องตรงกับตอนเทรน) ---\n",
        "def infer_classes_from_train_dir(train_dir: Path):\n",
        "    \"\"\"เดาลำดับคลาสจากชื่อโฟลเดอร์ย่อยใน train/ ตาม sorting ของ Keras\"\"\"\n",
        "    if not train_dir.exists():\n",
        "        return None\n",
        "    subdirs = [p.name for p in train_dir.iterdir() if p.is_dir()]\n",
        "    if not subdirs:\n",
        "        return None\n",
        "    return sorted(subdirs)  # image_dataset_from_directory ใช้ลำดับตาม sort แบบนี้\n",
        "\n",
        "DEFAULT_CLASSES = ['BB','BK','BN','BP','BQ','BR','Empty','WB','WK','WN','WP','WQ','WR']\n",
        "\n",
        "CLASSES = None\n",
        "if CLASSES_JSON.exists():\n",
        "    try:\n",
        "        CLASSES = json.loads(CLASSES_JSON.read_text(encoding=\"utf-8\"))\n",
        "        if not isinstance(CLASSES, list) or not all(isinstance(x, str) for x in CLASSES):\n",
        "            raise ValueError(\"classes.json format invalid\")\n",
        "    except Exception as e:\n",
        "        CLASSES = None  # ไป fallback ต่อ\n",
        "\n",
        "if CLASSES is None:\n",
        "    # พยายามเดาจากโฟลเดอร์ train/ ถ้ามี\n",
        "    guessed = infer_classes_from_train_dir(TRAIN_DIR)\n",
        "    if guessed and set(guessed) == set(DEFAULT_CLASSES) and len(guessed) == len(DEFAULT_CLASSES):\n",
        "        CLASSES = guessed\n",
        "    else:\n",
        "        CLASSES = DEFAULT_CLASSES  # สุดท้ายใช้ default ที่เราคอนโทรลได้\n",
        "\n",
        "# บันทึกลำดับคลาสล็อกไว้ (เพื่อให้ inference ครั้งต่อไปเหมือนตอนนี้เป๊ะ)\n",
        "try:\n",
        "    CLASSES_JSON.parent.mkdir(parents=True, exist_ok=True)\n",
        "    CLASSES_JSON.write_text(json.dumps(CLASSES, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "except Exception:\n",
        "    pass  # ถ้าเขียนไม่ได้ไม่เป็นไร\n",
        "\n",
        "# --- sanity checks / summary ---\n",
        "video_files = sorted(VIDEOS_DIR.glob(\"*.mp4\"))\n",
        "print(\"=== Environment ===\")\n",
        "print(\"Kaggle     :\", ON_KAGGLE)\n",
        "print(\"ROOT       :\", ROOT)\n",
        "print(\"Config     :\", cfg_source)\n",
        "print(\"Videos dir :\", VIDEOS_DIR)\n",
        "print(\"Model path :\", MODEL_PATH)\n",
        "print(\"Submit CSV :\", SUBMIT_CSV)\n",
        "print(\"Train dir  :\", TRAIN_DIR if TRAIN_DIR.exists() else \"[not found]\")\n",
        "print(\"IMG_SIZE   :\", IMG_SIZE)\n",
        "print(\"SMOOTH_K   :\", SMOOTH_K)\n",
        "print(\"SAMPLE_STEP:\", SAMPLE_STEP)\n",
        "print(\"Classes    :\", CLASSES)\n",
        "print(\"Videos found:\", len(video_files))\n",
        "\n",
        "# คำเตือนที่มีประโยชน์\n",
        "if not MODEL_PATH.exists():\n",
        "    print(\"[warn] MODEL_PATH not found ->\", MODEL_PATH)\n",
        "if not video_files:\n",
        "    print(\"[warn] No .mp4 files in:\", VIDEOS_DIR)\n",
        "if \"Empty\" not in CLASSES:\n",
        "    print(\"[warn] 'Empty' class is missing in CLASSES — results will be wrong for empty squares.\")\n",
        "if len(CLASSES) != 13:\n",
        "    print(f\"[warn] CLASSES has {len(CLASSES)} items (expected 13). Check your class order.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# --- load trained cell-CNN ---\n",
        "model = load_cell_model(str(MODEL_PATH))\n",
        "\n",
        "# ทำนาย 8×8 ด้วย smoothing buffer ต่อ cell\n",
        "def predict_labels8x8(warped_bgr, buffers):\n",
        "    cells = split_grid(warped_bgr, IMG_SIZE)\n",
        "    X = []\n",
        "    for _, patch in cells:\n",
        "        rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        X.append(preprocess_input(rgb))\n",
        "    X = np.asarray(X, dtype=np.float32)  # shape: (64, H, W, 3)\n",
        "\n",
        "    probs = model.predict(X, verbose=0)  # (64, num_classes)\n",
        "\n",
        "    mat = [[None]*8 for _ in range(8)]\n",
        "    k = 0\n",
        "    for r in range(8):\n",
        "        for c in range(8):\n",
        "            buffers[r][c].append(probs[k])\n",
        "            avg = np.mean(np.stack(buffers[r][c], axis=0), axis=0)\n",
        "            mat[r][c] = CLASSES[int(np.argmax(avg))]\n",
        "            k += 1\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chess\n",
        "\n",
        "def decode_video_to_pgn(video_path: Path) -> str:\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    ok, frame = cap.read()\n",
        "    if not ok:\n",
        "        cap.release()\n",
        "        return \"\"\n",
        "\n",
        "    # warp กระดานเฟรมแรก\n",
        "    warped, _ = warp_board(frame, {\"board\": BOARD_CFG})\n",
        "\n",
        "    # เตรียม buffer สำหรับ smoothing ต่อ cell\n",
        "    buffers = [[deque(maxlen=SMOOTH_K) for _ in range(8)] for __ in range(8)]\n",
        "    prev_labels = predict_labels8x8(warped, buffers)\n",
        "\n",
        "    sans = []\n",
        "    frame_id = 0\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "        frame_id += 1\n",
        "\n",
        "        # sample ทุก N เฟรม\n",
        "        if frame_id % SAMPLE_STEP:\n",
        "            continue\n",
        "\n",
        "        warped, _ = warp_board(frame, {\"board\": BOARD_CFG})\n",
        "        now_labels = predict_labels8x8(warped, buffers)\n",
        "\n",
        "        mv = diff_to_move(prev_labels, now_labels)\n",
        "        if mv is not None:\n",
        "            # ใช้ labels_to_board เพื่อสร้างกระดานก่อนหน้าที่ถูกต้อง → แปลงเป็น SAN\n",
        "            b_prev = labels_to_board(prev_labels)\n",
        "            san = b_prev.san(mv)\n",
        "            sans.append(san)\n",
        "            prev_labels = now_labels  # อัปเดต state\n",
        "\n",
        "    cap.release()\n",
        "    return san_list_to_pgn(sans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Decoding videos:  20%|██        | 1/5 [04:02<16:08, 242.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2_Move_rotate_student -> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Decoding videos:  40%|████      | 2/5 [08:38<13:07, 262.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2_move_student -> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Decoding videos:  60%|██████    | 3/5 [18:29<13:45, 412.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4_Move_studet -> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Decoding videos:  80%|████████  | 4/5 [28:29<08:06, 486.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6_Move_student -> \n"
          ]
        }
      ],
      "source": [
        "rows = []\n",
        "video_files = sorted(VIDEOS_DIR.glob(\"*.mp4\"))\n",
        "if not video_files:\n",
        "    print(f\"[warn] no videos found in: {VIDEOS_DIR}\")\n",
        "\n",
        "for v in tqdm(video_files, desc=\"Decoding videos\"):\n",
        "    row_id = v.stem\n",
        "    pgn = decode_video_to_pgn(v)\n",
        "    rows.append((row_id, pgn))\n",
        "    print(f\"{row_id} -> {pgn}\")\n",
        "\n",
        "with open(SUBMIT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"row_id\", \"output\"])\n",
        "    w.writerows(rows)\n",
        "\n",
        "print(\"✅ submission saved to:\", SUBMIT_CSV.resolve())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv312 (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
