{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 ‚Äî Build Cell Dataset (Kaggle‚ÄëReady)\n",
    "\n",
    "This notebook converts a **Roboflow COCO (Object Detection)** chess dataset into **per‚Äëcell patches (13 classes)** for training a per‚Äëcell CNN.\n",
    "\n",
    "- **Input (preferred on Kaggle):** `/kaggle/input/chess-pieces-roboflow-coco/` (COCO JSON)\n",
    "- **Output:** `./data/final/train|val/<CLASS>/*.jpg`\n",
    "- **Classes:** `Empty, WP, WN, WB, WR, WQ, WK, BP, BN, BB, BR, BQ, BK`\n",
    "\n",
    "> Runs both **locally** (repo layout) and on **Kaggle**. If paths don't exist, the cell will skip gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Basic deps (Kaggle has most preinstalled; keep minimal)\n",
    "# !pip install --quiet opencv-python pycocotools tqdm pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON_KAGGLE = False\n",
      "‚úÖ Created folders for 13 classes (including Empty)\n",
      "ROBO_ROOT = C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\public\\roboflow_coco\n",
      "OUT_ROOT  = C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\n"
     ]
    }
   ],
   "source": [
    "import os, json, cv2, shutil, random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# --- Detect if Kaggle ---\n",
    "ON_KAGGLE = Path('/kaggle').exists()\n",
    "print(\"ON_KAGGLE =\", ON_KAGGLE)\n",
    "\n",
    "# --- Paths ---\n",
    "if ON_KAGGLE:\n",
    "    # Adjust this to the Roboflow COCO dataset folder name you uploaded to Kaggle Datasets\n",
    "    ROBO_ROOT = Path('/kaggle/input/chess-pieces-coco')  # <-- change if your dataset slug differs\n",
    "    # Expected structure inside ROBO_ROOT: train/, valid/, test/, each with _annotations.coco.json\n",
    "    OUT_ROOT = Path('/kaggle/working')  # writeable\n",
    "else:\n",
    "    # local repo layout (relative to this notebook in /notebooks/)\n",
    "    ROBO_ROOT = Path('../data/public/roboflow_coco')\n",
    "    OUT_ROOT  = Path('..')\n",
    "\n",
    "# Output dirs (follow repo config)\n",
    "CELLS_PUBLIC    = OUT_ROOT / 'data/public/cells'\n",
    "CELLS_BOOTSTRAP = OUT_ROOT / 'data/bootstrap/cells'\n",
    "FINAL_TRAIN     = OUT_ROOT / 'data/final/train'\n",
    "FINAL_VAL       = OUT_ROOT / 'data/final/val'\n",
    "\n",
    "# Create dirs\n",
    "for p in [CELLS_PUBLIC, CELLS_BOOTSTRAP, FINAL_TRAIN, FINAL_VAL]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# Image size for per-cell patches\n",
    "IMG_SIZE = 96  # keep in sync with model config\n",
    "\n",
    "# Cell: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 13 classes\n",
    "CLASSES_13 = [\"Empty\",\"WP\",\"WN\",\"WB\",\"WR\",\"WQ\",\"WK\",\"BP\",\"BN\",\"BB\",\"BR\",\"BQ\",\"BK\"]\n",
    "\n",
    "# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏ß‡∏° Empty)\n",
    "for c in CLASSES_13:\n",
    "    os.makedirs(CELLS_PUBLIC / c, exist_ok=True)\n",
    "    os.makedirs(CELLS_BOOTSTRAP / c, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Created folders for 13 classes (including Empty)\")\n",
    "\n",
    "print(\"ROBO_ROOT =\", ROBO_ROOT.resolve())\n",
    "print(\"OUT_ROOT  =\", OUT_ROOT.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) map ‡∏ä‡∏∑‡πà‡∏≠ + extractor (‡∏ß‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô) ---\n",
    "NAME_MAP = {\n",
    "    \"white-pawn\":\"WP\",\"white-rook\":\"WR\",\"white-knight\":\"WN\",\"white-bishop\":\"WB\",\"white-queen\":\"WQ\",\"white-king\":\"WK\",\n",
    "    \"black-pawn\":\"BP\",\"black-rook\":\"BR\",\"black-knight\":\"BN\",\"black-bishop\":\"BB\",\"black-queen\":\"BQ\",\"black-king\":\"BK\",\n",
    "}\n",
    "\n",
    "def extract_from_coco(coco_json, imgs_dir, out_root, img_size):\n",
    "    import json, cv2\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with open(coco_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    id_to_file     = {img[\"id\"]: img[\"file_name\"] for img in data.get(\"images\", [])}\n",
    "    cat_id_to_name = {c[\"id\"]:  c[\"name\"]        for c   in data.get(\"categories\", [])}\n",
    "\n",
    "    boxes_by_img = {}\n",
    "    for ann in data.get(\"annotations\", []):\n",
    "        if ann.get(\"iscrowd\", 0) not in (0, None): \n",
    "            continue\n",
    "        cls_name_raw = cat_id_to_name.get(ann[\"category_id\"], \"\")\n",
    "        mapped = NAME_MAP.get(cls_name_raw)\n",
    "        if not mapped:\n",
    "            continue\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        boxes_by_img.setdefault(ann[\"image_id\"], []).append((mapped, (x, y, w, h)))\n",
    "\n",
    "    total = 0\n",
    "    for img_id, bbox_list in tqdm(boxes_by_img.items(), desc=f\"Cropping {coco_json.stem}\"):\n",
    "        fn = id_to_file.get(img_id)\n",
    "        if not fn: \n",
    "            continue\n",
    "        img = cv2.imread(str(imgs_dir / fn))\n",
    "        if img is None:\n",
    "            continue\n",
    "        H, W = img.shape[:2]\n",
    "        idx = 0\n",
    "        for mapped, (x, y, w, h) in bbox_list:\n",
    "            x1 = max(0, int(round(x))); y1 = max(0, int(round(y)))\n",
    "            x2 = min(W, int(round(x+w))); y2 = min(H, int(round(y+h)))\n",
    "            if x2 <= x1 or y2 <= y1: \n",
    "                continue\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            if crop.size == 0: \n",
    "                continue\n",
    "            crop = cv2.resize(crop, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "            out_dir = CELLS_PUBLIC / mapped\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            if cv2.imwrite(str(out_dir / f\"{img_id}_{idx}.jpg\"), crop):\n",
    "                total += 1; idx += 1\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO category name -> our 12 piece labels\n",
    "COCO2OUR = {\n",
    "    \"white-pawn\":\"WP\", \"white-rook\":\"WR\", \"white-knight\":\"WN\", \"white-bishop\":\"WB\", \"white-queen\":\"WQ\", \"white-king\":\"WK\",\n",
    "    \"black-pawn\":\"BP\", \"black-rook\":\"BR\", \"black-knight\":\"BN\", \"black-bishop\":\"BB\", \"black-queen\":\"BQ\", \"black-king\":\"BK\",\n",
    "}\n",
    "\n",
    "def extract_from_coco(coco_json_path: Path, images_dir: Path, out_dir: Path, img_size: int) -> int:\n",
    "    \"\"\"Extract bbox crops from a COCO JSON into per-class folders as square patches.\"\"\"\n",
    "    if not coco_json_path.exists():\n",
    "        print(f\"[skip] no COCO at {coco_json_path}\")\n",
    "        return 0\n",
    "\n",
    "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    id2file = {im[\"id\"]: im[\"file_name\"] for im in coco.get(\"images\", [])}\n",
    "    cat_id2name = {c[\"id\"]: c[\"name\"] for c in coco.get(\"categories\", [])}\n",
    "    anns_by_img = {}\n",
    "    for ann in coco.get(\"annotations\", []):\n",
    "        anns_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "    saved = 0\n",
    "    for img_id, anns in tqdm(anns_by_img.items(), desc=f\"Extract {images_dir.name}\"):\n",
    "        img_path = images_dir / id2file.get(img_id, \"\")\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        H, W = img.shape[:2]\n",
    "        for i, ann in enumerate(anns):\n",
    "            cname = cat_id2name.get(ann[\"category_id\"], None)\n",
    "            lab = COCO2OUR.get(cname, None)\n",
    "            if lab is None:\n",
    "                continue\n",
    "            x,y,w,h = ann[\"bbox\"]\n",
    "            x0,y0 = max(0,int(x)), max(0,int(y))\n",
    "            x1,y1 = min(W,int(x+w)), min(H,int(y+h))\n",
    "            if x1<=x0 or y1<=y0: \n",
    "                continue\n",
    "            crop = img[y0:y1, x0:x1]\n",
    "            crop = cv2.resize(crop, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "            fname = f\"{img_path.stem}_{i}.jpg\"\n",
    "            cv2.imwrite(str(out_dir / lab / fname), crop)\n",
    "            saved += 1\n",
    "    return saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 606/606 [00:05<00:00, 120.57it/s]\n",
      "Extract valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [00:00<00:00, 105.64it/s]\n",
      "Extract test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 66.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved patches from Roboflow = 7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for split in [\"train\",\"valid\",\"test\"]:\n",
    "    coco_json = ROBO_ROOT / split / \"_annotations.coco.json\"\n",
    "    imgs_dir  = ROBO_ROOT / split\n",
    "    if coco_json.exists():\n",
    "        total += extract_from_coco(coco_json, imgs_dir, CELLS_PUBLIC, IMG_SIZE)\n",
    "    else:\n",
    "        print(f\"[warn] missing split: {split}\")\n",
    "print(\"Saved patches from Roboflow =\", total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Bootstrap from class videos (first-frame ‚Üí auto labels)\n",
    "\n",
    "- On **Kaggle**, hidden test videos are not available ‚Üí this step is **skipped**.\n",
    "- Locally, put class videos in `../data/public/videos/*.mp4` then run the cell below **after** you have `src/board.py` & `src/cells.py` available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip bootstrap step since we already have the data from earlier runs\n",
    "print(\"Skipping bootstrap step - using existing data\")\n",
    "print(f\"CELLS_BOOTSTRAP contains the Empty cells already extracted\")\n",
    "\n",
    "# Count existing files\n",
    "empty_bootstrap = list((CELLS_BOOTSTRAP / \"Empty\").glob(\"*.jpg\"))\n",
    "print(f\"Found {len(empty_bootstrap)} Empty cells in bootstrap\")\n",
    "\n",
    "if len(empty_bootstrap) == 0:\n",
    "    print(\"Warning: No Empty cells found. You may need to run the bootstrap extraction manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìÅ Empty Dataset Location Check\n",
      "============================================================\n",
      "CELLS_BOOTSTRAP/Empty: 1084 files\n",
      "CELLS_PUBLIC/Empty: 0 files\n",
      "Total: 1084 files\n",
      "============================================================\n",
      "\n",
      "‚úÖ Sample from bootstrap: ..\\data\\bootstrap\\cells\\Empty\\2_Move_rotate_student_20.jpg\n",
      "\n",
      "üìÇ CELLS_BOOTSTRAP = C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\bootstrap\\cells\n",
      "üìÇ CELLS_PUBLIC = C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\public\\cells\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
    "empty_bootstrap = list((CELLS_BOOTSTRAP / \"Empty\").glob(\"*.jpg\"))\n",
    "empty_public = list((CELLS_PUBLIC / \"Empty\").glob(\"*.jpg\"))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìÅ Empty Dataset Location Check\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CELLS_BOOTSTRAP/Empty: {len(empty_bootstrap)} files\")\n",
    "print(f\"CELLS_PUBLIC/Empty: {len(empty_public)} files\")\n",
    "print(f\"Total: {len(empty_bootstrap) + len(empty_public)} files\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "if empty_bootstrap:\n",
    "    print(f\"\\n‚úÖ Sample from bootstrap: {empty_bootstrap[0]}\")\n",
    "if empty_public:\n",
    "    print(f\"‚úÖ Sample from public: {empty_public[0]}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á path ‡πÄ‡∏ï‡πá‡∏°\n",
    "print(f\"\\nüìÇ CELLS_BOOTSTRAP = {CELLS_BOOTSTRAP.resolve()}\")\n",
    "print(f\"üìÇ CELLS_PUBLIC = {CELLS_PUBLIC.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping augmentation - using existing dataset\n",
      "CELLS_BOOTSTRAP/Empty: 1084 files\n",
      "CELLS_PUBLIC/Empty: 0 files\n",
      "Total: 1084 files\n",
      "SUCCESS: Sufficient Empty cells for training!\n"
     ]
    }
   ],
   "source": [
    "# Skip augmentation since we already have sufficient Empty cells\n",
    "print(\"Skipping augmentation - using existing dataset\")\n",
    "\n",
    "empty_bootstrap = list((CELLS_BOOTSTRAP / \"Empty\").glob(\"*.jpg\"))\n",
    "empty_public = list((CELLS_PUBLIC / \"Empty\").glob(\"*.jpg\"))\n",
    "\n",
    "print(f\"CELLS_BOOTSTRAP/Empty: {len(empty_bootstrap)} files\")\n",
    "print(f\"CELLS_PUBLIC/Empty: {len(empty_public)} files\") \n",
    "print(f\"Total: {len(empty_bootstrap) + len(empty_public)} files\")\n",
    "\n",
    "if len(empty_bootstrap) + len(empty_public) >= 300:\n",
    "    print(\"SUCCESS: Sufficient Empty cells for training!\")\n",
    "else:\n",
    "    print(\"WARNING: May need more Empty cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying existing dataset...\n",
      "======================================================================\n",
      "üìä DATASET COMPARISON\n",
      "======================================================================\n",
      "\n",
      "üî¥ OLD DATASET (data/final/train + val) - IMBALANCED:\n",
      "----------------------------------------------------------------------\n",
      "Empty  train= 815  val=  90  total= 905 ‚ö†Ô∏è LOW!\n",
      "   WP  train=2913  val= 323  total=3236\n",
      "   WN  train= 850  val=  94  total= 944\n",
      "   WB  train= 774  val=  86  total= 860\n",
      "   WR  train= 842  val=  93  total= 935\n",
      "   WQ  train= 497  val=  55  total= 552\n",
      "   WK  train= 653  val=  72  total= 725\n",
      "   BP  train=3025  val= 336  total=3361\n",
      "   BN  train= 876  val=  97  total= 973\n",
      "   BB  train= 616  val=  68  total= 684\n",
      "   BR  train= 907  val= 100  total=1007\n",
      "   BQ  train= 387  val=  43  total= 430\n",
      "   BK  train= 635  val=  70  total= 705\n",
      "\n",
      "Total: train=13790 val=1527 grand_total=15317\n",
      "\n",
      "‚úÖ NEW BALANCED DATASET (data/balanced/cells) - FIXED:\n",
      "----------------------------------------------------------------------\n",
      "Empty  1784 images ‚ú® IMPROVED!\n",
      "   WP  3236 images\n",
      "   WN   944 images\n",
      "   WB   860 images\n",
      "   WR   935 images\n",
      "   WQ   552 images\n",
      "   WK   725 images\n",
      "   BP  3361 images\n",
      "   BN   973 images\n",
      "   BB   684 images\n",
      "   BR  1007 images\n",
      "   BQ   430 images\n",
      "   BK   705 images\n",
      "\n",
      "Total: 16196 images\n",
      "\n",
      "======================================================================\n",
      "üéØ Empty cell improvement: 815 ‚Üí 1784 (2.2x increase!)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Balanced dataset ready for retraining!\n",
      "   This will fix the Empty cell classification problem!\n"
     ]
    }
   ],
   "source": [
    "# Dataset already exists from previous run - just verify it\n",
    "print(\"Verifying existing dataset...\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# OLD dataset (original)\n",
    "FINAL_TRAIN = Path('../data/final/train')\n",
    "FINAL_VAL = Path('../data/final/val')\n",
    "\n",
    "# NEW balanced dataset (with augmented Empty cells)\n",
    "BALANCED_CELLS = Path('../data/balanced/cells')\n",
    "\n",
    "CLASSES_13 = [\"Empty\",\"WP\",\"WN\",\"WB\",\"WR\",\"WQ\",\"WK\",\"BP\",\"BN\",\"BB\",\"BR\",\"BQ\",\"BK\"]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä DATASET COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show OLD dataset\n",
    "if FINAL_TRAIN.exists() and FINAL_VAL.exists():\n",
    "    print(\"\\nüî¥ OLD DATASET (data/final/train + val) - IMBALANCED:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    total_train = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    for c in CLASSES_13:\n",
    "        train_count = len(list((FINAL_TRAIN / c).glob(\"*.jpg\"))) if (FINAL_TRAIN / c).exists() else 0\n",
    "        val_count = len(list((FINAL_VAL / c).glob(\"*.jpg\"))) if (FINAL_VAL / c).exists() else 0\n",
    "        total = train_count + val_count\n",
    "        total_train += train_count\n",
    "        total_val += val_count\n",
    "        \n",
    "        # Highlight Empty class\n",
    "        marker = \" ‚ö†Ô∏è LOW!\" if c == \"Empty\" else \"\"\n",
    "        print(f\"{c:>5}  train={train_count:4d}  val={val_count:4d}  total={total:4d}{marker}\")\n",
    "    \n",
    "    print(f\"\\nTotal: train={total_train} val={total_val} grand_total={total_train + total_val}\")\n",
    "\n",
    "# Show NEW balanced dataset\n",
    "if BALANCED_CELLS.exists():\n",
    "    print(\"\\n‚úÖ NEW BALANCED DATASET (data/balanced/cells) - FIXED:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    total_balanced = 0\n",
    "    \n",
    "    for c in CLASSES_13:\n",
    "        count = len(list((BALANCED_CELLS / c).glob(\"*.jpg\"))) if (BALANCED_CELLS / c).exists() else 0\n",
    "        total_balanced += count\n",
    "        \n",
    "        # Highlight Empty class improvement\n",
    "        marker = \" ‚ú® IMPROVED!\" if c == \"Empty\" else \"\"\n",
    "        print(f\"{c:>5}  {count:4d} images{marker}\")\n",
    "    \n",
    "    print(f\"\\nTotal: {total_balanced} images\")\n",
    "    \n",
    "    # Show the improvement\n",
    "    old_empty = len(list((FINAL_TRAIN / \"Empty\").glob(\"*.jpg\"))) if (FINAL_TRAIN / \"Empty\").exists() else 0\n",
    "    new_empty = len(list((BALANCED_CELLS / \"Empty\").glob(\"*.jpg\"))) if (BALANCED_CELLS / \"Empty\").exists() else 0\n",
    "    \n",
    "    print(\"\\n\"+\"=\"*70)\n",
    "    print(f\"üéØ Empty cell improvement: {old_empty} ‚Üí {new_empty} ({new_empty/old_empty:.1f}x increase!)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n‚úÖ Balanced dataset ready for retraining!\")\n",
    "    print(\"   This will fix the Empty cell classification problem!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NEW balanced dataset not found!\")\n",
    "    print(\"   Run: python scripts/fix_dataset_balance.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv312 (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
