{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 — Build Cell Dataset (Kaggle‑Ready)\n",
        "\n",
        "This notebook converts a **Roboflow COCO (Object Detection)** chess dataset into **per‑cell patches (13 classes)** for training a per‑cell CNN.\n",
        "\n",
        "- **Input (preferred on Kaggle):** `/kaggle/input/chess-pieces-roboflow-coco/` (COCO JSON)\n",
        "- **Output:** `./data/final/train|val/<CLASS>/*.jpg`\n",
        "- **Classes:** `Empty, WP, WN, WB, WR, WQ, WK, BP, BN, BB, BR, BQ, BK`\n",
        "\n",
        "> Runs both **locally** (repo layout) and on **Kaggle**. If paths don't exist, the cell will skip gracefully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# Basic deps (Kaggle has most preinstalled; keep minimal)\n",
        "# !pip install --quiet opencv-python pycocotools tqdm pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ON_KAGGLE = False\n",
            "ROBO_ROOT = C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\public\\roboflow_coco\n",
            "OUT_ROOT  = C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\n"
          ]
        }
      ],
      "source": [
        "import os, json, cv2, shutil, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# --- Detect if Kaggle ---\n",
        "ON_KAGGLE = Path('/kaggle').exists()\n",
        "print(\"ON_KAGGLE =\", ON_KAGGLE)\n",
        "\n",
        "# --- Paths ---\n",
        "if ON_KAGGLE:\n",
        "    # Adjust this to the Roboflow COCO dataset folder name you uploaded to Kaggle Datasets\n",
        "    ROBO_ROOT = Path('/kaggle/input/chess-pieces-coco')  # <-- change if your dataset slug differs\n",
        "    # Expected structure inside ROBO_ROOT: train/, valid/, test/, each with _annotations.coco.json\n",
        "    OUT_ROOT = Path('/kaggle/working')  # writeable\n",
        "else:\n",
        "    # local repo layout (relative to this notebook in /notebooks/)\n",
        "    ROBO_ROOT = Path('../data/public/roboflow_coco')\n",
        "    OUT_ROOT  = Path('..')\n",
        "\n",
        "# Output dirs (follow repo config)\n",
        "CELLS_PUBLIC    = OUT_ROOT / 'data/public/cells'\n",
        "CELLS_BOOTSTRAP = OUT_ROOT / 'data/bootstrap/cells'\n",
        "FINAL_TRAIN     = OUT_ROOT / 'data/final/train'\n",
        "FINAL_VAL       = OUT_ROOT / 'data/final/val'\n",
        "\n",
        "# Create dirs\n",
        "for p in [CELLS_PUBLIC, CELLS_BOOTSTRAP, FINAL_TRAIN, FINAL_VAL]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "# Image size for per-cell patches\n",
        "IMG_SIZE = 96  # keep in sync with model config\n",
        "\n",
        "CLASSES_13 = [\"Empty\",\"WP\",\"WN\",\"WB\",\"WR\",\"WQ\",\"WK\",\"BP\",\"BN\",\"BB\",\"BR\",\"BQ\",\"BK\"]\n",
        "for c in CLASSES_13[1:]:  # 'Empty' will be populated via bootstrap later\n",
        "    os.makedirs(CELLS_PUBLIC / c, exist_ok=True)\n",
        "\n",
        "print(\"ROBO_ROOT =\", ROBO_ROOT.resolve())\n",
        "print(\"OUT_ROOT  =\", OUT_ROOT.resolve())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 1) map ชื่อ + extractor (วางก่อน) ---\n",
        "NAME_MAP = {\n",
        "    \"white-pawn\":\"WP\",\"white-rook\":\"WR\",\"white-knight\":\"WN\",\"white-bishop\":\"WB\",\"white-queen\":\"WQ\",\"white-king\":\"WK\",\n",
        "    \"black-pawn\":\"BP\",\"black-rook\":\"BR\",\"black-knight\":\"BN\",\"black-bishop\":\"BB\",\"black-queen\":\"BQ\",\"black-king\":\"BK\",\n",
        "}\n",
        "\n",
        "def extract_from_coco(coco_json, imgs_dir, out_root, img_size):\n",
        "    import json, cv2\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    with open(coco_json, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    id_to_file     = {img[\"id\"]: img[\"file_name\"] for img in data.get(\"images\", [])}\n",
        "    cat_id_to_name = {c[\"id\"]:  c[\"name\"]        for c   in data.get(\"categories\", [])}\n",
        "\n",
        "    boxes_by_img = {}\n",
        "    for ann in data.get(\"annotations\", []):\n",
        "        if ann.get(\"iscrowd\", 0) not in (0, None): \n",
        "            continue\n",
        "        cls_name_raw = cat_id_to_name.get(ann[\"category_id\"], \"\")\n",
        "        mapped = NAME_MAP.get(cls_name_raw)\n",
        "        if not mapped:\n",
        "            continue\n",
        "        x, y, w, h = ann[\"bbox\"]\n",
        "        boxes_by_img.setdefault(ann[\"image_id\"], []).append((mapped, (x, y, w, h)))\n",
        "\n",
        "    total = 0\n",
        "    for img_id, bbox_list in tqdm(boxes_by_img.items(), desc=f\"Cropping {coco_json.stem}\"):\n",
        "        fn = id_to_file.get(img_id)\n",
        "        if not fn: \n",
        "            continue\n",
        "        img = cv2.imread(str(imgs_dir / fn))\n",
        "        if img is None:\n",
        "            continue\n",
        "        H, W = img.shape[:2]\n",
        "        idx = 0\n",
        "        for mapped, (x, y, w, h) in bbox_list:\n",
        "            x1 = max(0, int(round(x))); y1 = max(0, int(round(y)))\n",
        "            x2 = min(W, int(round(x+w))); y2 = min(H, int(round(y+h)))\n",
        "            if x2 <= x1 or y2 <= y1: \n",
        "                continue\n",
        "            crop = img[y1:y2, x1:x2]\n",
        "            if crop.size == 0: \n",
        "                continue\n",
        "            crop = cv2.resize(crop, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
        "            out_dir = CELLS_PUBLIC / mapped\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            if cv2.imwrite(str(out_dir / f\"{img_id}_{idx}.jpg\"), crop):\n",
        "                total += 1; idx += 1\n",
        "    return total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COCO category name -> our 12 piece labels\n",
        "COCO2OUR = {\n",
        "    \"white-pawn\":\"WP\", \"white-rook\":\"WR\", \"white-knight\":\"WN\", \"white-bishop\":\"WB\", \"white-queen\":\"WQ\", \"white-king\":\"WK\",\n",
        "    \"black-pawn\":\"BP\", \"black-rook\":\"BR\", \"black-knight\":\"BN\", \"black-bishop\":\"BB\", \"black-queen\":\"BQ\", \"black-king\":\"BK\",\n",
        "}\n",
        "\n",
        "def extract_from_coco(coco_json_path: Path, images_dir: Path, out_dir: Path, img_size: int) -> int:\n",
        "    \"\"\"Extract bbox crops from a COCO JSON into per-class folders as square patches.\"\"\"\n",
        "    if not coco_json_path.exists():\n",
        "        print(f\"[skip] no COCO at {coco_json_path}\")\n",
        "        return 0\n",
        "\n",
        "    with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    id2file = {im[\"id\"]: im[\"file_name\"] for im in coco.get(\"images\", [])}\n",
        "    cat_id2name = {c[\"id\"]: c[\"name\"] for c in coco.get(\"categories\", [])}\n",
        "    anns_by_img = {}\n",
        "    for ann in coco.get(\"annotations\", []):\n",
        "        anns_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
        "\n",
        "    saved = 0\n",
        "    for img_id, anns in tqdm(anns_by_img.items(), desc=f\"Extract {images_dir.name}\"):\n",
        "        img_path = images_dir / id2file.get(img_id, \"\")\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            continue\n",
        "        H, W = img.shape[:2]\n",
        "        for i, ann in enumerate(anns):\n",
        "            cname = cat_id2name.get(ann[\"category_id\"], None)\n",
        "            lab = COCO2OUR.get(cname, None)\n",
        "            if lab is None:\n",
        "                continue\n",
        "            x,y,w,h = ann[\"bbox\"]\n",
        "            x0,y0 = max(0,int(x)), max(0,int(y))\n",
        "            x1,y1 = min(W,int(x+w)), min(H,int(y+h))\n",
        "            if x1<=x0 or y1<=y0: \n",
        "                continue\n",
        "            crop = img[y0:y1, x0:x1]\n",
        "            crop = cv2.resize(crop, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
        "            fname = f\"{img_path.stem}_{i}.jpg\"\n",
        "            cv2.imwrite(str(out_dir / lab / fname), crop)\n",
        "            saved += 1\n",
        "    return saved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cropping _annotations.coco: 100%|██████████| 606/606 [00:06<00:00, 97.96it/s] \n",
            "Cropping _annotations.coco: 100%|██████████| 58/58 [00:00<00:00, 125.21it/s]\n",
            "Cropping _annotations.coco: 100%|██████████| 28/28 [00:00<00:00, 67.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved patches from Roboflow = 7083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "total = 0\n",
        "for split in [\"train\",\"valid\",\"test\"]:\n",
        "    coco_json = ROBO_ROOT / split / \"_annotations.coco.json\"\n",
        "    imgs_dir  = ROBO_ROOT / split\n",
        "    if coco_json.exists():\n",
        "        total += extract_from_coco(coco_json, imgs_dir, CELLS_PUBLIC, IMG_SIZE)\n",
        "    else:\n",
        "        print(f\"[warn] missing split: {split}\")\n",
        "print(\"Saved patches from Roboflow =\", total)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Bootstrap from class videos (first-frame → auto labels)\n",
        "\n",
        "- On **Kaggle**, hidden test videos are not available → this step is **skipped**.\n",
        "- Locally, put class videos in `../data/public/videos/*.mp4` then run the cell below **after** you have `src/board.py` & `src/cells.py` available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved bootstrap patches: 320\n"
          ]
        }
      ],
      "source": [
        "from Chess_Detection_Competition.utils import load_config\n",
        "from Chess_Detection_Competition.cells import bootstrap_from_first_frame\n",
        "\n",
        "# โหลด config เต็มจาก configs/parameters.yaml (มีทั้ง board/cells/train/...)\n",
        "cfg = load_config()\n",
        "\n",
        "# ชี้โฟลเดอร์วิดีโอตาม config (จะได้ไม่พังถ้าย้ายที่)\n",
        "VIDEOS_DIR = OUT_ROOT / cfg[\"paths\"][\"videos_dir\"]   # เดิมคุณใช้ OUT_ROOT/'data/public/videos'\n",
        "saved_boot = 0\n",
        "\n",
        "try:\n",
        "    if VIDEOS_DIR.exists():\n",
        "        for v in sorted(VIDEOS_DIR.glob(\"*.mp4\")):\n",
        "            saved_boot += bootstrap_from_first_frame(\n",
        "                str(v),\n",
        "                str(CELLS_BOOTSTRAP),\n",
        "                cfg,                         # <<<< สำคัญ: ส่ง cfg ทั้งก้อน\n",
        "            )\n",
        "        print(\"Saved bootstrap patches:\", saved_boot)\n",
        "    else:\n",
        "        print(\"[skip] no videos dir found:\", VIDEOS_DIR)\n",
        "except Exception:\n",
        "    import traceback\n",
        "    print(\"[skip] bootstrap step error:\\n\", traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty  train= 144  val=  16\n",
            "   WP  train=2877  val= 319\n",
            "   WN  train= 841  val=  93\n",
            "   WB  train= 765  val=  85\n",
            "   WR  train= 833  val=  92\n",
            "   WQ  train= 493  val=  54\n",
            "   WK  train= 648  val=  72\n",
            "   BP  train=2989  val= 332\n",
            "   BN  train= 867  val=  96\n",
            "   BB  train= 607  val=  67\n",
            "   BR  train= 898  val=  99\n",
            "   BQ  train= 383  val=  42\n",
            "   BK  train= 630  val=  70\n",
            "\n",
            "✅ Done. Final dataset at:\n",
            "   C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\final\\train\n",
            "   C:\\Users\\worap\\Downloads\\image_processing_term_orject\\Chess_Detection_Competition\\data\\final\\val\n"
          ]
        }
      ],
      "source": [
        "def copy_merge_split(src_dirs, out_train, out_val, classes, val_ratio=0.1, seed=2025):\n",
        "    for c in classes:\n",
        "        os.makedirs(out_train / c, exist_ok=True)\n",
        "        os.makedirs(out_val / c, exist_ok=True)\n",
        "\n",
        "    rng = random.Random(seed)\n",
        "    for c in classes:\n",
        "        pool = []\n",
        "        for sd in src_dirs:\n",
        "            p = Path(sd) / c\n",
        "            if p.exists():\n",
        "                pool += [str(p / f) for f in os.listdir(p) if f.lower().endswith(('.jpg','.png'))]\n",
        "        rng.shuffle(pool)\n",
        "        n_val = max(1, int(len(pool)*val_ratio))\n",
        "        val_set = pool[:n_val]\n",
        "        tr_set  = pool[n_val:]\n",
        "        for s in tr_set:\n",
        "            shutil.copy(s, out_train / c / os.path.basename(s))\n",
        "        for s in val_set:\n",
        "            shutil.copy(s, out_val / c / os.path.basename(s))\n",
        "        print(f\"{c:>5}  train={len(tr_set):4d}  val={len(val_set):4d}\")\n",
        "\n",
        "# Merge Roboflow crops (+ optional bootstrap) → final train/val\n",
        "srcs = [CELLS_PUBLIC, CELLS_BOOTSTRAP]\n",
        "copy_merge_split(srcs, FINAL_TRAIN, FINAL_VAL, CLASSES_13, val_ratio=0.1)\n",
        "print(\"\\n✅ Done. Final dataset at:\") \n",
        "print(\"  \", FINAL_TRAIN.resolve())\n",
        "print(\"  \", FINAL_VAL.resolve())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv312 (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
